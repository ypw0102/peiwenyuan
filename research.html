
<!doctype html>
<html lang="en">
  <head>
  <script src="https://use.fontawesome.com/baff6f55f5.js"></script>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Peiwen Yuan(袁沛文)</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/github-light.css">
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=yes">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
      ga('create', 'UA-29643011-3', 'auto');
      ga('send', 'pageview');
    </script>

    <!-- New GA4 tracking code, see https://support.google.com/analytics/answer/10271001#analyticsjs-enable-basic --> 
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-GNJD50R0Z7"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'G-GNJD50R0Z7');
    </script>

    <!-- For all browsers -->
    <link rel="stylesheet" href="assets/css/academicons.min.css"/>
    <link rel="stylesheet" href="assets/css/academicons.css"/>
    
    <style>
      button.accordion {
      font:14px/1.5 Lato, "Helvetica Neue", Helvetica, Arial, sans-serif;
      cursor: pointer;
      padding: 0px;
      border: none;
      text-align: left;
      outline: none;
      font-size: 100%;
      transition: 0.3s;
      background-color: #f8f8f8;
      }
      button.accordion.active, button.accordion:hover {
      background-color: #f8f8f8;
      }
      button.accordion:after {
      content: " [+] ";
      font-size: 90%;
      color:#777;
      float: left;
      margin-left: 1px;
      }

      button.accordion.active:after {
      content: " [\2212] ";
      }
      div.panel {
      padding: 0 20px;
      margin-top: 5px;
      display: none;
      background-color: white;
      font-size: 100%;
      }
      div.panel.show {
      display: block !important;
      }
      .social-row {
        display: flex;
        flex-wrap: wrap;
        justify-content: space-between;
      }
    </style>
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1>Peiwen Yuan(袁沛文)</h1>
        <p>PhD candidate advised by <a href="https://dblp.org/pid/21/2083-1.html">Kan Li</a><br>Beijing Institute of Technology(北京理工大学)</p>
    <h3><a href=" https://ypw0102.github.io/peiwenyuan.github.io/">Home</a></h3>
        <h3><a href=" https://ypw0102.github.io/peiwenyuan.github.io/research.html">Research</a></h3>
        <h3><a href=" https://ypw0102.github.io/peiwenyuan.github.io/personal.html">Personal</a></h3>
    <b>Social</b><br>
        <div class="social-row">
          <a href="mailto:678ypw@gmail.com" target="_blank"><i class="fa fa-fw fa-envelope-square"></i> Email</a><br>
          <a href="https://scholar.google.com.hk/citations?user=cUB5XN8AAAAJ&hl=zh-CN&oi=ao" target="_blank"><i class="ai ai-fw ai-google-scholar-square"></i> Scholar</a><br>
          <a href="https://github.com/ypw0102"><i class="fa fa-fw fa-github-square"></i> GitHub</a><br>
          <br>
        </div>
        <br>

    <p><b>Contact:</b><br>WeChat: Y20000102_pw<br>or email above</p>
    <p><small>Hosted on GitHub Pages &mdash; Theme by <a href="https://github.com/orderedlist">orderedlist</a></small></p>

      </header>
      <section>

    <h2><a id="recent-RRs-updated" class="anchor" href="#RRpapers" aria-hidden="true"><span class="octicon octicon-link"></span></a>Papers Under Review</h2>
    <p style="margin:0"> <b>Poor-Supervised Evaluation for SuperLLM via Mutual Consistency</b> <br>  Peiwen Yuan, Shaoxiong Feng, Yiwei Li, Xinglin Wang, Boyuan Pan Heda Wang, Kan Li <br> <b>Submitted to <i>ACL2024</i></b> <br><button class="accordion">
      Abstract
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> The guidance from capability evaluations has greatly propelled the progress of human society and the development of Artificial Intelligence. However, as LLMs evolve, it becomes challenging to construct evaluation benchmark with accurate labels for SuperLLMs whose capabilities approach or even surpass those of humans. To credibly conduct evaluation without accurate labels (denoted as poor-supervised evaluation), we first prove that the consistency between the model under evaluation and the reference model, when their prediction distributions are independent and the sample size is infinite, can equivalently assess the true capabilities of the model to be evaluated. However, using either humans or LLMs as the reference model cannot sufficiently meet the conditions, for which we propose the PEEM algorithm. By treating all models under evaluation as reference models, PEEM alternately optimizes model weights and filters reference models based on EM algorithm to maximally alleviate the insufficiency of the conditions. Comprehensive experiments across 3 types of tasks with 16 mainstream LLMs validate the efficiency, universality, and effectiveness of PEEM. More generally, PEEM has advanced the evaluation paradigm evolution from human-centric to human&model-centric, alleviating the limitations of human capabilities for evaluating SuperLLMs. </p></div>
    <br>
        
    <p style="margin:0"> <a style="margin:0; font-size:100%; font-weight:bold" href="https://arxiv.org/abs/2401.00437v1">BatchEval: Towards Human-like Text Evaluation</a> <br> Peiwen Yuan, Shaoxiong Feng, Yiwei Li, Xinglin Wang, Boyuan Pan, Heda Wang, Kan Li <br> <b>Submitted to <i>ACL2024</i></b> <br><button class="accordion"> 
    Abstract   
    </button>   
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> Significant progress has been made in automatic text evaluation with the introduction of large language models (LLMs) as evaluators. However, current sample-wise evaluation paradigm suffers from the following issues: (1) Sensitive to prompt design; (2) Poor resistance to noise; (3) Inferior ensemble performance with static reference. Inspired by the fact that humans treat both criterion definition and inter sample comparison as references for evaluation, we propose BatchEval, a paradigm that conducts batch-wise evaluation iteratively to alleviate the above problems. We explore variants under this paradigm and confirm the optimal settings are two stage procedure with heterogeneous batch composition strategy and decimal scoring format. Comprehensive experiments across 3 LLMs on 4 text evaluation tasks demonstrate that BatchEval outperforms state-of-the-art methods by 10.5% on Pearson correlations with only 64% API cost on average. Further analyses have been conducted to verify the robustness, generalization, and working mechanism of BatchEval. </p></div>
    <p style="margin:0"><button class="accordion">
      Data&Code
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> <a href="https://github.com/ypw0102/BatchEval">Data &amp; code for replication</a>  </p></div>
    <p style="margin:0"><button class="accordion">
      BibTeX citation
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> <pre> <code>
@article{yuan2023batcheval,
  title={BatchEval: Towards Human-like Text Evaluation},
  author={Yuan, Peiwen and Feng, Shaoxiong and Li, Yiwei and Wang, Xinglin and Pan, Boyuan and Wang, Heda and Li, Kan},
  journal={arXiv preprint arXiv:2401.00437},
  year={2023}
}
</code> </pre> </p></div><br>

    <hr>

    <h2><a id="published-papers-updated" class="anchor" href="#publications" aria-hidden="true"><span class="octicon octicon-link"></span></a>Published &amp; Forthcoming Papers</h2>
        <p style="margin:0"> <a style="margin:0; font-size:100%; font-weight:bold" href="https://arxiv.org/abs/2401.00437v1">BatchEval: Towards Human-like Text Evaluation</a> <br> Peiwen Yuan, Shaoxiong Feng, Yiwei Li, Xinglin Wang, Boyuan Pan, Heda Wang, Kan Li <br> <b>Submitted to <i>ACL2024</i></b> <br><button class="accordion"> 
    Abstract   
    </button>   
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> Significant progress has been made in automatic text evaluation with the introduction of large language models (LLMs) as evaluators. However, current sample-wise evaluation paradigm suffers from the following issues: (1) Sensitive to prompt design; (2) Poor resistance to noise; (3) Inferior ensemble performance with static reference. Inspired by the fact that humans treat both criterion definition and inter sample comparison as references for evaluation, we propose BatchEval, a paradigm that conducts batch-wise evaluation iteratively to alleviate the above problems. We explore variants under this paradigm and confirm the optimal settings are two stage procedure with heterogeneous batch composition strategy and decimal scoring format. Comprehensive experiments across 3 LLMs on 4 text evaluation tasks demonstrate that BatchEval outperforms state-of-the-art methods by 10.5% on Pearson correlations with only 64% API cost on average. Further analyses have been conducted to verify the robustness, generalization, and working mechanism of BatchEval. </p></div>
    <p style="margin:0"><button class="accordion">
      Data&Code
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> <a href="https://github.com/ypw0102/BatchEval">Data &amp; code for replication</a>  </p></div>
    <p style="margin:0"><button class="accordion">
      BibTeX citation
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> <pre> <code>
@article{yuan2023batcheval,
  title={BatchEval: Towards Human-like Text Evaluation},
  author={Yuan, Peiwen and Feng, Shaoxiong and Li, Yiwei and Wang, Xinglin and Pan, Boyuan and Wang, Heda and Li, Kan},
  journal={arXiv preprint arXiv:2401.00437},
  year={2023}
}
</code> </pre> </p></div><br>
        
      </section>
    </div>
    <script src="javascripts/scale.fix.js"></script>
    <script> 
    var acc = document.getElementsByClassName("accordion");
    var i;

    for (i = 0; i < acc.length; i++) {
        acc[i].onclick = function(){
            this.classList.toggle("active");
            this.parentNode.nextElementSibling.classList.toggle("show");
      }
    }
    </script>
  </body>
</html>
